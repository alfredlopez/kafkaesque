<?xml version="1.0" encoding="UTF-8"?>
<configuration>

  <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
    <layout class="ch.qos.logback.classic.PatternLayout">
      <Pattern>%d{yyyy-MM-dd-HH:mm:ss.SSS} [%thread] %-5level %logger{36} [%F:%L] - %msg%n</Pattern>
    </layout>
  </appender>

  <timestamp key="bySecond" datePattern="yyyyMMdd'T'HHmmss"/>

  <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>logs/kafka-${bySecond}.log</file>
    <append>true</append>
    <!-- set immediateFlush to false for much higher logging throughput -->
    <immediateFlush>true</immediateFlush>
    <!-- encoders are assigned the type
         ch.qos.logback.classic.encoder.PatternLayoutEncoder by default -->
    <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
      <!-- rollover daily -->
      <fileNamePattern>logs/kafka-%d{yyyyMMdd}.%i.log</fileNamePattern>
      <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
      <maxFileSize>100MB</maxFileSize>
      <maxHistory>20</maxHistory>
      <totalSizeCap>2GB</totalSizeCap>
    </rollingPolicy>
    <encoder>
<!--      <pattern>%d{yyyy-MM-dd-HH:mm:ss.SSS} [%thread] %-5level %logger{36} [%F:%L] - %msg%n</pattern>-->
      <pattern>%d{yyyy-MM-dd-HH:mm:ss.SSS} %logger{36} [%F:%L] - %msg%n</pattern>
    </encoder>
  </appender>

<!--  <logger name="kafka" level="ERROR">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--    <appender-ref ref="FILE" />-->
<!--  </logger>-->

<!--  <logger name="kafka.server" level="ERROR">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--    <appender-ref ref="FILE" />-->
<!--  </logger>-->

<!--  <logger name="org.apache.zookeeper.ClientCnxn" level="ERROR">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--&lt;!&ndash;    <appender-ref ref="FILE" />&ndash;&gt;-->
<!--  </logger>-->

<!--  <logger name="org.apache.kafka.connect" level="DEBUG">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--    <appender-ref ref="FILE" />-->
<!--  </logger>-->

<!--  <logger name="io.confluent.connect.jdbc" level="DEBUG">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--    <appender-ref ref="FILE" />-->
<!--  </logger>-->

<!--  <logger name="com.asanasoft.common.handlers" level="INFO">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--&lt;!&ndash;    <appender-ref ref="FILE" />&ndash;&gt;-->
<!--  </logger>-->

<!--    <logger name="com.asanasoft.app.kafkaesque" level="DEBUG">-->
<!--        <appender-ref ref="STDOUT" />-->
<!--        <appender-ref ref="FILE" />-->
<!--    </logger>-->

<!--  <logger name="com.asanasoft.common.init.impl.GraphQLInitializer" level="DEBUG">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--&lt;!&ndash;    <appender-ref ref="FILE" />&ndash;&gt;-->
<!--  </logger>-->

<!--  <logger name="com.asanasoft.common.verticle.ShellInstance" level="TRACE">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--&lt;!&ndash;    <appender-ref ref="FILE" />&ndash;&gt;-->
<!--  </logger>-->

<!--  <logger name="com.asanasoft.common.service.graphdb.impl.AbstractGraphDBService" level="INFO">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--&lt;!&ndash;    <appender-ref ref="FILE" />&ndash;&gt;-->
<!--  </logger>-->

<!--  <logger name="com.asanasoft.common.handlers.KafkaConnectProxyHandler" level="TRACE">-->
<!--    <appender-ref ref="STDOUT" />-->
<!--  </logger>-->

  <logger name="io.vertx.core.impl.BlockedThreadChecker" level="ERROR">
    <appender-ref ref="STDOUT" />
  </logger>

  <root level="INFO">
    <appender-ref ref="STDOUT" />
    <appender-ref ref="FILE" />
  </root>
</configuration>
